{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Preamble for most code and jupyter notebooks\n",
    "@author: tobinsouth\n",
    "@notebook date: 28 Oct 2021\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, matplotlib as mpl, seaborn as sns\n",
    "import math, string, re, pickle, json, os, sys, datetime, itertools\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set panda's options\n",
    "pd.set_option(\"display.max_rows\", 50)\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "\n",
    "# Better graphics\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "plt.style.use('seaborn-poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class StaysDataset(Dataset):\n",
    "    \"\"\"Loads in stayz dataset as zipped csv files\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir):\n",
    "        from glob import glob\n",
    "        self.root_dir = root_dir\n",
    "        self.all_csvs = glob(root_dir+'/*.csv.gz')\n",
    "        stays = pd.concat([pd.read_csv(csv, nrows = 100000) for csv in self.all_csvs])\n",
    "\n",
    "        self.all_users = list(stays['user'].unique())\n",
    "        self.grouped_users = stays.groupby('user')\n",
    "        self.user_homes = dict(self.grouped_users['GEOID_home'].unique())\n",
    "        self.grouped_stays = self.grouped_users['GEOID']\n",
    "        self.all_geoid = list(set(list(stays['GEOID'].unique()) + [l.item() for l in self.user_homes.values()]))\n",
    "        self.all_geoid_mapping = dict(zip(self.all_geoid, range(1,len(self.all_geoid)+1)))\n",
    "\n",
    "        # We could also truncate each time they leave home?\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_users)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get item from grouped frame\"\"\"\n",
    "        user = self.all_users[idx]\n",
    "        user_stays_seq = self.grouped_stays.get_group(user).to_list()\n",
    "        user_home = self.user_homes[user].item()\n",
    "        user_stays_seq = [self.all_geoid_mapping[user_home]] + [self.all_geoid_mapping[geoid] for geoid in user_stays_seq]\n",
    "        user_stays_seq = torch.tensor(user_stays_seq, dtype=torch.long)\n",
    "        return user_stays_seq\n",
    "\n",
    "\n",
    "root_dir = '../data/'\n",
    "staysDataset = StaysDataset(root_dir)\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "dataloader = DataLoader(staysDataset, batch_size=1, shuffle=True, \n",
    "    collate_fn=lambda batch: pad_sequence(batch, batch_first=True, padding_value=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SentEnc(nn.Module):\n",
    "    def __init__(self, num_locations, hidden_size, dropout=0):\n",
    "        super(SentEnc, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_locations, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, dropout=dropout, batch_first=True)\n",
    "        self.linear =  nn.Linear(hidden_size, num_locations)      \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        loc_space = self.linear(lstm_out)\n",
    "        return loc_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 64\n",
    "batch_size = 32\n",
    "num_layers = 1\n",
    "num_epochs = 3 \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "dropout = 0\n",
    "\n",
    "lstm = SentEnc(len(staysDataset.all_geoid), HIDDEN_SIZE, dropout)\n",
    "optimizer = torch.optim.Adam(lstm.parameters()) \n",
    "\n",
    "# # Training LSTM next step prediction on sequences\n",
    "# for epoch in range(num_epochs):\n",
    "#     for seq_batch in dataloader:\n",
    "#         seq_batch = seq_batch.to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         lstm_out = lstm(seq_batch)\n",
    "#         loss = criterion(lstm_out, seq_batch)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_batch in dataloader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(seq_batch.shape)\n",
    "x = lstm.embedding(seq_batch)\n",
    "print(x.shape)\n",
    "lstm_out, _ = lstm.lstm(x)\n",
    "lstm.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "all_csvs = glob(root_dir+'/*.csv.gz')\n",
    "stays = pd.concat([pd.read_csv(csv, nrows = 100000) for csv in all_csvs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user, seq in stays.groupby('user')['GEOID']:\n",
    "    seq = torch.tensor([staysDataset.all_geoid_mapping[geoid] for geoid in seq]).reshape(1,-1)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
