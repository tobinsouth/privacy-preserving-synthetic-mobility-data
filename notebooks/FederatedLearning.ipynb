{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differentially private learning of embedding spaces.\n",
    "\n",
    "https://towardsdatascience.com/preserving-data-privacy-in-deep-learning-part-1-a04894f78029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clients = 10\n",
    "batch_size = 1\n",
    "lr =  0.001\n",
    "epochs = 10\n",
    "local_epochs = 1\n",
    "\n",
    "# Loss function params\n",
    "k = 0.0025\n",
    "x0 =2500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "We're going to need to reprocess the data so that we group each user to have their own mobility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../scripts'); from dataloader import MobilitySeqDataset\n",
    "\n",
    "staysDataset = MobilitySeqDataset(root_dir='/mas/projects/privacy-pres-mobility/data/processed_data/', dataset='cuebiq')\n",
    "\n",
    "# Dividing the training data into num_clients, with each client having equal number of images\n",
    "splits_lengths = [len(staysDataset) // (num_clients+1) for _ in range(num_clients+1)]\n",
    "data_split = torch.utils.data.random_split(staysDataset, splits_lengths +[len(staysDataset) - sum(splits_lengths)])\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "collate_fn=lambda batch: pad_sequence(batch, batch_first=True, padding_value=0)\n",
    "splitloader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True, collate_fn=collate_fn) for x in data_split]\n",
    "\n",
    "trainingSplits = splitloader[:-1]\n",
    "testSplit = splitloader[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom loss function from paper\n",
    "NLL = torch.nn.NLLLoss(ignore_index=0, reduction='sum')\n",
    "\n",
    "def loss_fn(logp, target, mean, logv, step, k, x0):\n",
    "    \"\"\"The loss function used in the paper, taken from https://github.com/timbmg/Sentence-VAE\"\"\"\n",
    "    target = target.view(-1)\n",
    "    logp = logp.view(-1, logp.size(2))\n",
    "\n",
    "    # Negative Log Likelihood\n",
    "    NLL_loss = NLL(logp, target)\n",
    "\n",
    "    # KL Divergence\n",
    "    KL_loss = -0.5 * torch.sum(1 + logv - mean.pow(2) - logv.exp())\n",
    "    KL_weight = float(1/(1+np.exp(-k*(step-x0))))\n",
    "\n",
    "    return NLL_loss, KL_loss, KL_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_update(client_model, optimizer, train_loader, local_epochs=1):\n",
    "    \"\"\"\n",
    "    This function updates/trains client model on client data\n",
    "    \"\"\"\n",
    "    step = 0\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for e in range(local_epochs):\n",
    "        for batch in tqdm(train_loader, desc=\"Client Epoch {}\".format(e), position=0):\n",
    "            batch = batch.to(device)\n",
    "            logp, mean, logv, z = client_model(batch)\n",
    "            NLL_loss, KL_loss, KL_weight = loss_fn(logp, batch, mean, logv, step, k, x0)\n",
    "            loss = (NLL_loss + KL_weight * KL_loss) / batch_size\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            step += 1\n",
    "            total_loss += loss.item()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def server_aggregate(global_model, client_models):\n",
    "    \"\"\"\n",
    "    This function has aggregation method 'mean'\n",
    "    \"\"\"\n",
    "    ### This will take simple mean of the weights of models ###\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    \"\"\"This function test the global model on test data and returns test loss and test accuracy \"\"\"\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            logp, mean, logv, z = model(batch)\n",
    "            NLL_loss, KL_loss, KL_weight = loss_fn(logp, batch, mean, logv, step, k, x0)\n",
    "            loss = (NLL_loss + KL_weight * KL_loss) / batch_size\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../scripts');\n",
    "from VAE import SentenceVAE, device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientModel(SentenceVAE):\n",
    "    \"\"\"A little class for each client model\"\"\"\n",
    "    def __init__(self, **params):\n",
    "        super().__init__(**params)\n",
    "        self.name = 'Client Model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    vocab_size = testSplit.dataset.dataset._vocab_size,\n",
    "    max_sequence_length = testSplit.dataset.dataset._max_seq_len,\n",
    "    embedding_size = 256,\n",
    "    rnn_type =  'gru',\n",
    "    hidden_size = 256,\n",
    "    num_layers = 1,\n",
    "    bidirectional = False,\n",
    "    latent_size = 16,\n",
    "    word_dropout = 0,\n",
    "    embedding_dropout = 0.5,\n",
    "    sos_idx=0,\n",
    "    eos_idx=0,\n",
    "    pad_idx=0,\n",
    "    unk_idx=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### global model ##########\n",
    "global_model =  SentenceVAE(**params).to(device)\n",
    "\n",
    "############## client models ##############\n",
    "client_models = [ SentenceVAE(**params).to(device) for _ in range(num_clients)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict()) ### initial synchronizing with global model \n",
    "\n",
    "############### optimizers ################\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizers = [torch.optim.Adam(model.parameters(), lr=lr) for model in client_models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Client Epoch 0:   4%|‚ñç         | 19790/517605 [02:05<54:20, 152.68it/s]  "
     ]
    }
   ],
   "source": [
    "losses_train = []\n",
    "losses_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    loss = 0\n",
    "    for i in tqdm(range(num_clients), desc='Global Loop', position=0):\n",
    "        loss += client_update(client_models[i], optimizers[i], trainingSplits[i], local_epochs=local_epochs)\n",
    "    \n",
    "    losses_train.append(loss)\n",
    "    \n",
    "    # server aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    \n",
    "    test_loss, acc = test(global_model, testSplit)\n",
    "    losses_test.append(test_loss)\n",
    "    acc_test.append(acc)\n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_clients, test_loss, acc))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c854730bd06fef4a089243d2501fb3b7e98cc6cf4ccc2cce9e8cdf48ee542ef6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
